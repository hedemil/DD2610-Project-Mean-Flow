# Training config for limited compute (local GPU)
# This is a minimal config to demonstrate training capability
# Not expected to achieve good FID scores due to compute constraints

model:
    cls: DiT_S_4  # Start with smaller model for 16x16x16 voxels
    input_size: 16  # Override default 32 -> 16x16 spatial size
    in_channels: 16  # 16 depth slices as channels

dataset:
    name: mnist3d_latent  # Contains 'latent' so uses LatentDataset
    root: data/mnist3d_latents
    image_size: 16  # Spatial: 16x16 (depth becomes channels)
    image_channels: 16  # Depth dimension treated as 16 channels
    num_classes: 10  # 10 digits


training:
    # Critical: Small batch size for local GPU
    batch_size: 64  # Increased for better gradients (was 4)

    # Short training for demonstration
    num_epochs: 500  # Reduced from 240. Enough to show loss curve

    learning_rate: 0.0001  # Back to 1e-4 (1e-5 was too conservative)
    adam_b2: 0.999  # Fixed: was 0.95, should be 0.999 per MeanFlow reference
    ema_type: 'const'
    ema_val: 0.99995  # Fixed: was 0.9999, should be 0.99995 per reference

    # Logging and checkpointing
    log_per_step: 10
    checkpoint_per_epoch: 50  # More frequent checkpointing
    keep_checkpoints: 5  # Keep more checkpoints for safety

    # Sampling during training
    sample_on_training: true
    sample_per_epoch: 5  # Generate samples more frequently

    # Evaluation (NEW!)
    eval_on_training: true  # Enable evaluation
    eval_per_epoch: 100  # Evaluate every 100 epochs
    eval_batch_size: 100  # Number of samples to generate for evaluation
    eval_num_real: 100  # Number of real samples to compare against

    # FID evaluation
    fid_per_epoch: 50  # More frequent FID calculation

    seed: 42
    half_precision: false

fid:
    # FID is disabled for 3D data (Inception network expects RGB images)
    device_batch_size: 2
    num_samples: 2000
    cache_ref: /home/emil/KTH/Adv. Deep Learning/Project/DD2610-Project-Mean-Flow/meanflow-jax/imagenet_fid_stats.npz
    on_training: false  # Disabled: FID not applicable for 3D voxel data

sampling:
    num_steps: 1  # Single-step sampling
    num_classes: 10  # Override default 1000 -> 10 for MNIST
    seed: 42

# Evaluation metrics
evaluation:
    # Chamfer Distance (point cloud similarity)
    chamfer_threshold: -0.5  # Voxel threshold for foreground (captures full digit structure)
    chamfer_enabled: true

    # Voxel IoU
    iou_threshold: -0.5  # Match Chamfer threshold for consistency
    iou_enabled: true

    # FID disabled for 3D MNIST
    fid_views: ['xy', 'xz', 'yz']
    fid_enabled: false

    # Early stopping (optional)
    early_stopping_metric: 'chamfer_distance'
    early_stopping_patience: 50  # Stop if no improvement for 50 epochs
    early_stopping_min_delta: 0.01

# Don't load checkpoint (train from scratch)
load_from: null
eval_only: False

# Method parameters (keep defaults for now)
method:
    P_mean: -0.4
    P_std: 1.0
    class_dropout_prob: 0.1
    data_proportion: 1.0
    guidance_eq: cfg
    kappa: 0.5
    noise_dist: logit_normal
    norm_eps: 0.01
    norm_p: 1.0
    omega: 1.0
    t_end: 1.0
    t_start: 0.0
